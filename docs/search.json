[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kush Desai",
    "section": "",
    "text": "Welcome to my website!"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is Project 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\nKush Desai\nApr 19, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "This is Project 1",
    "section": "",
    "text": "This is Project 1"
  },
  {
    "objectID": "blog/project2/index.html",
    "href": "blog/project2/index.html",
    "title": "This is Project 2",
    "section": "",
    "text": "This is Project 2"
  },
  {
    "objectID": "blog/project1/hw1_questions.html",
    "href": "blog/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment randomly assigned individuals to receive either a standard fundraising letter or one that included a matching grant offer at different match ratios: $1:$1, $2:$1, or $3:$1. Some letters also varied the maximum amount that would be matched ($25,000, $50,000, $100,000, or unstated) and included different suggested donation amounts based on the recipient’s previous giving history. The researchers then tracked donation response rates and amounts to evaluate how price framing and match incentives affected giving behavior. This design allowed them to isolate the impact of price-based incentives while preserving the realism of a natural fundraising campaign.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#introduction",
    "href": "blog/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment randomly assigned individuals to receive either a standard fundraising letter or one that included a matching grant offer at different match ratios: $1:$1, $2:$1, or $3:$1. Some letters also varied the maximum amount that would be matched ($25,000, $50,000, $100,000, or unstated) and included different suggested donation amounts based on the recipient’s previous giving history. The researchers then tracked donation response rates and amounts to evaluate how price framing and match incentives affected giving behavior. This design allowed them to isolate the impact of price-based incentives while preserving the realism of a natural fundraising campaign.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#data",
    "href": "blog/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\n\ndata = pd.read_stata(\"karlan_list_2007.dta\")\n\ndata_shape = data.shape\n\ndata_head = data.head()\n\ndata_info = data.info()\n\ndata_description = data.describe()\n\ndata_shape, data_head, data_description\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 50083 entries, 0 to 50082\nData columns (total 51 columns):\n #   Column              Non-Null Count  Dtype   \n---  ------              --------------  -----   \n 0   treatment           50083 non-null  int8    \n 1   control             50083 non-null  int8    \n 2   ratio               50083 non-null  category\n 3   ratio2              50083 non-null  int8    \n 4   ratio3              50083 non-null  int8    \n 5   size                50083 non-null  category\n 6   size25              50083 non-null  int8    \n 7   size50              50083 non-null  int8    \n 8   size100             50083 non-null  int8    \n 9   sizeno              50083 non-null  int8    \n 10  ask                 50083 non-null  category\n 11  askd1               50083 non-null  int8    \n 12  askd2               50083 non-null  int8    \n 13  askd3               50083 non-null  int8    \n 14  ask1                50083 non-null  int16   \n 15  ask2                50083 non-null  int16   \n 16  ask3                50083 non-null  int16   \n 17  amount              50083 non-null  float32 \n 18  gave                50083 non-null  int8    \n 19  amountchange        50083 non-null  float32 \n 20  hpa                 50083 non-null  float32 \n 21  ltmedmra            50083 non-null  int8    \n 22  freq                50083 non-null  int16   \n 23  years               50082 non-null  float64 \n 24  year5               50083 non-null  int8    \n 25  mrm2                50082 non-null  float64 \n 26  dormant             50083 non-null  int8    \n 27  female              48972 non-null  float64 \n 28  couple              48935 non-null  float64 \n 29  state50one          50083 non-null  int8    \n 30  nonlit              49631 non-null  float64 \n 31  cases               49631 non-null  float64 \n 32  statecnt            50083 non-null  float32 \n 33  stateresponse       50083 non-null  float32 \n 34  stateresponset      50083 non-null  float32 \n 35  stateresponsec      50080 non-null  float32 \n 36  stateresponsetminc  50080 non-null  float32 \n 37  perbush             50048 non-null  float32 \n 38  close25             50048 non-null  float64 \n 39  red0                50048 non-null  float64 \n 40  blue0               50048 non-null  float64 \n 41  redcty              49978 non-null  float64 \n 42  bluecty             49978 non-null  float64 \n 43  pwhite              48217 non-null  float32 \n 44  pblack              48047 non-null  float32 \n 45  page18_39           48217 non-null  float32 \n 46  ave_hh_sz           48221 non-null  float32 \n 47  median_hhincome     48209 non-null  float64 \n 48  powner              48214 non-null  float32 \n 49  psch_atlstba        48215 non-null  float32 \n 50  pop_propurban       48217 non-null  float32 \ndtypes: category(3), float32(16), float64(12), int16(4), int8(16)\nmemory usage: 8.9 MB\n\n\n((50083, 51),\n    treatment  control    ratio  ratio2  ratio3      size  size25  size50  \\\n 0          0        1  Control       0       0   Control       0       0   \n 1          0        1  Control       0       0   Control       0       0   \n 2          1        0        1       0       0  $100,000       0       0   \n 3          1        0        1       0       0  Unstated       0       0   \n 4          1        0        1       0       0   $50,000       0       1   \n \n    size100  sizeno  ... redcty  bluecty    pwhite    pblack  page18_39  \\\n 0        0       0  ...    0.0      1.0  0.446493  0.527769   0.317591   \n 1        0       0  ...    1.0      0.0       NaN       NaN        NaN   \n 2        1       0  ...    0.0      1.0  0.935706  0.011948   0.276128   \n 3        0       1  ...    1.0      0.0  0.888331  0.010760   0.279412   \n 4        0       0  ...    0.0      1.0  0.759014  0.127421   0.442389   \n \n    ave_hh_sz  median_hhincome    powner  psch_atlstba  pop_propurban  \n 0       2.10          28517.0  0.499807      0.324528            1.0  \n 1        NaN              NaN       NaN           NaN            NaN  \n 2       2.48          51175.0  0.721941      0.192668            1.0  \n 3       2.65          79269.0  0.920431      0.412142            1.0  \n 4       1.85          40908.0  0.416072      0.439965            1.0  \n \n [5 rows x 51 columns],\n           treatment       control        ratio2        ratio3        size25  \\\n count  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \n mean       0.666813      0.333187      0.222311      0.222211      0.166723   \n std        0.471357      0.471357      0.415803      0.415736      0.372732   \n min        0.000000      0.000000      0.000000      0.000000      0.000000   \n 25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n 50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n 75%        1.000000      1.000000      0.000000      0.000000      0.000000   \n max        1.000000      1.000000      1.000000      1.000000      1.000000   \n \n              size50       size100        sizeno         askd1         askd2  \\\n count  50083.000000  50083.000000  50083.000000  50083.000000  50083.000000   \n mean       0.166623      0.166723      0.166743      0.222311      0.222291   \n std        0.372643      0.372732      0.372750      0.415803      0.415790   \n min        0.000000      0.000000      0.000000      0.000000      0.000000   \n 25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n 50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n 75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n max        1.000000      1.000000      1.000000      1.000000      1.000000   \n \n        ...        redcty       bluecty        pwhite        pblack  \\\n count  ...  49978.000000  49978.000000  48217.000000  48047.000000   \n mean   ...      0.510245      0.488715      0.819599      0.086710   \n std    ...      0.499900      0.499878      0.168560      0.135868   \n min    ...      0.000000      0.000000      0.009418      0.000000   \n 25%    ...      0.000000      0.000000      0.755845      0.014729   \n 50%    ...      1.000000      0.000000      0.872797      0.036554   \n 75%    ...      1.000000      1.000000      0.938827      0.090882   \n max    ...      1.000000      1.000000      1.000000      0.989622   \n \n           page18_39     ave_hh_sz  median_hhincome        powner  \\\n count  48217.000000  48221.000000     48209.000000  48214.000000   \n mean       0.321694      2.429012     54815.700533      0.669418   \n std        0.103039      0.378105     22027.316665      0.193405   \n min        0.000000      0.000000      5000.000000      0.000000   \n 25%        0.258311      2.210000     39181.000000      0.560222   \n 50%        0.305534      2.440000     50673.000000      0.712296   \n 75%        0.369132      2.660000     66005.000000      0.816798   \n max        0.997544      5.270000    200001.000000      1.000000   \n \n        psch_atlstba  pop_propurban  \n count  48215.000000   48217.000000  \n mean       0.391661       0.871968  \n std        0.186599       0.258633  \n min        0.000000       0.000000  \n 25%        0.235647       0.884929  \n 50%        0.373744       1.000000  \n 75%        0.530036       1.000000  \n max        1.000000       1.000000  \n \n [8 rows x 48 columns])\n\n\nThe dataset contains 50,083 observations and 51 variables, each representing a prior donor who received a fundraising letter as part of a large-scale field experiment. Each row captures the characteristics of a single solicitation, including the treatment received (e.g., whether a matching grant was offered), attributes of the treatment (such as match ratio and suggested donation amount), and outcomes (e.g., whether the person gave and how much).\nThe variables span multiple data types, including binary indicators (treatment, control, ratio2, gave), categorical labels (ratio, size, ask), and continuous variables (amount, amountchange, median_hhincome). A subset of the variables describe donor behavior, while others reflect demographic or political attributes of the donor’s region (e.g., pwhite, psch_atlstba, perbush).\nMost variables are complete, though a few—such as female, couple, and zip-code-level demographic indicators—contain some missing values. These variables will be useful for subgroup analysis or robustness checks later in the analysis.\nBelow is a table listing each variable and its definition.\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport pandas as pd\nimport scipy.stats as stats\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\ndata = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Drop rows with missing data in the selected covariates\nsubset = data[['mrm2', 'years', 'female', 'nonlit', 'treatment']].dropna()\n\n# T-test for mrm2\nt_mrm2 = stats.ttest_ind(\n    subset.loc[subset['treatment'] == 1, 'mrm2'],\n    subset.loc[subset['treatment'] == 0, 'mrm2'],\n    equal_var=False\n)\n\n# Linear regression: mrm2 ~ treatment\nmodel_mrm2 = smf.ols('mrm2 ~ treatment', data=subset).fit()\n\n# Repeat for 'years'\nt_years = stats.ttest_ind(\n    subset.loc[subset['treatment'] == 1, 'years'],\n    subset.loc[subset['treatment'] == 0, 'years'],\n    equal_var=False\n)\nmodel_years = smf.ols('years ~ treatment', data=subset).fit()\n\n# Female (binary)\nt_female = stats.ttest_ind(\n    subset.loc[subset['treatment'] == 1, 'female'],\n    subset.loc[subset['treatment'] == 0, 'female'],\n    equal_var=False\n)\nmodel_female = smf.ols('female ~ treatment', data=subset).fit()\n\n# Nonlit\nt_nonlit = stats.ttest_ind(\n    subset.loc[subset['treatment'] == 1, 'nonlit'],\n    subset.loc[subset['treatment'] == 0, 'nonlit'],\n    equal_var=False\n)\nmodel_nonlit = smf.ols('nonlit ~ treatment', data=subset).fit()\n\n# Output\n{\n    \"T-Test Results\": {\n        \"mrm2\": t_mrm2,\n        \"years\": t_years,\n        \"female\": t_female,\n        \"nonlit\": t_nonlit\n    },\n    \"Regression Coefs (treatment)\": {\n        \"mrm2\": model_mrm2.params['treatment'],\n        \"years\": model_years.params['treatment'],\n        \"female\": model_female.params['treatment'],\n        \"nonlit\": model_nonlit.params['treatment']\n    },\n    \"P-Values\": {\n        \"mrm2\": model_mrm2.pvalues['treatment'],\n        \"years\": model_years.pvalues['treatment'],\n        \"female\": model_female.pvalues['treatment'],\n        \"nonlit\": model_nonlit.pvalues['treatment']\n    }\n}\n\n{'T-Test Results': {'mrm2': TtestResult(statistic=0.10979476165416026, pvalue=0.9125728262179356, df=32366.36309248335),\n  'years': TtestResult(statistic=-1.0948992897288046, pvalue=0.2735691436031105, df=31455.998443012893),\n  'female': TtestResult(statistic=-1.8424593791305501, pvalue=0.06541719238550407, df=32124.51606241337),\n  'nonlit': TtestResult(statistic=1.581732537538529, pvalue=0.11372035684297054, df=32552.057508370406)},\n 'Regression Coefs (treatment)': {'mrm2': 0.012753705751466927,\n  'years': -0.05879664418677571,\n  'female': -0.007968707925652073,\n  'nonlit': 0.0298005445033021},\n 'P-Values': {'mrm2': 0.9125634444738681,\n  'years': 0.26837184186459406,\n  'female': 0.06463086890487692,\n  'nonlit': 0.11445428186637126}}\n\n\nTo evaluate whether the randomization successfully produced balanced treatment and control groups, I tested four pre-treatment covariates: mrm2 (months since last donation), years (years since initial donation), female, and nonlit (non-litigation activity in state). For each variable, I ran both a two-sample t-test and a simple linear regression with the variable as the outcome and treatment as the independent variable.\nThe results show no statistically significant differences at the 5% level between treatment and control for any of the covariates. Specifically, p-values from the t-tests were all above 0.05 (mrm2: 0.913, years: 0.274, nonlit: 0.114), except for female which was marginally significant (p = 0.065). These results were confirmed by the corresponding regression analyses.\nTaken together, the evidence suggests that the treatment and control groups are well balanced across key pre-treatment variables, supporting the internal validity of the experimental design. This aligns with the findings shown in Table 1 of the original Karlan and List (2007) paper."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#experimental-results",
    "href": "blog/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndata = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Create donation rates\ndonation_rates = data.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\n\n# Bar plot\nplt.bar(labels, donation_rates, color=['gray', 'blue'])\nplt.ylabel('Proportion Who Donated')\nplt.title('Charitable Contribution Rate by Group')\nplt.ylim(0, 0.05)\nplt.show()\n\n# Drop missing values\nsubset = data[['gave', 'treatment']].dropna()\n\n# T-test\nfrom scipy.stats import ttest_ind\nt_gave = ttest_ind(\n    subset.loc[subset['treatment'] == 1, 'gave'],\n    subset.loc[subset['treatment'] == 0, 'gave'],\n    equal_var=False\n)\n\n# Linear regression\nimport statsmodels.formula.api as smf\nmodel_gave = smf.ols('gave ~ treatment', data=subset).fit()\n\nimport statsmodels.api as sm\n# Probit model\nprobit_model = smf.probit('gave ~ treatment', data=subset).fit()\nt_gave, model_gave.summary(),probit_model.summary()\n\n\n\n\n\n\n\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n\n\n(TtestResult(statistic=3.2094621908279835, pvalue=0.001330982345091417, df=36576.84238986656),\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                             OLS Regression Results                            \n ==============================================================================\n Dep. Variable:                   gave   R-squared:                       0.000\n Model:                            OLS   Adj. R-squared:                  0.000\n Method:                 Least Squares   F-statistic:                     9.618\n Date:                Sat, 19 Apr 2025   Prob (F-statistic):            0.00193\n Time:                        22:04:04   Log-Likelihood:                 26630.\n No. Observations:               50083   AIC:                        -5.326e+04\n Df Residuals:                   50081   BIC:                        -5.324e+04\n Df Model:                           1                                         \n Covariance Type:            nonrobust                                         \n ==============================================================================\n                  coef    std err          t      P&gt;|t|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept      0.0179      0.001     16.225      0.000       0.016       0.020\n treatment      0.0042      0.001      3.101      0.002       0.002       0.007\n ==============================================================================\n Omnibus:                    59814.280   Durbin-Watson:                   2.005\n Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4317152.727\n Skew:                           6.740   Prob(JB):                         0.00\n Kurtosis:                      46.440   Cond. No.                         3.23\n ==============================================================================\n \n Notes:\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n \"\"\",\n &lt;class 'statsmodels.iolib.summary.Summary'&gt;\n \"\"\"\n                           Probit Regression Results                           \n ==============================================================================\n Dep. Variable:                   gave   No. Observations:                50083\n Model:                         Probit   Df Residuals:                    50081\n Method:                           MLE   Df Model:                            1\n Date:                Sat, 19 Apr 2025   Pseudo R-squ.:               0.0009783\n Time:                        22:04:04   Log-Likelihood:                -5030.5\n converged:                       True   LL-Null:                       -5035.4\n Covariance Type:            nonrobust   LLR p-value:                  0.001696\n ==============================================================================\n                  coef    std err          z      P&gt;|z|      [0.025      0.975]\n ------------------------------------------------------------------------------\n Intercept     -2.1001      0.023    -90.073      0.000      -2.146      -2.054\n treatment      0.0868      0.028      3.113      0.002       0.032       0.141\n ==============================================================================\n \"\"\")\n\n\nTo analyze whether matching donations increased the likelihood of giving, I first plotted the share of donors in the treatment and control groups. The barplot clearly shows a higher proportion of individuals donating in the treatment group.\nStatistical analysis confirms this difference. A t-test comparing the proportion of donors in each group yields a p-value of 0.0013, indicating the difference is statistically significant. A linear regression of gave on the treatment variable finds a coefficient of 0.0042 (p &lt; 0.01), meaning that being assigned to the matching treatment increased donation likelihood by approximately 0.42 percentage points.\nTo further confirm the robustness of this finding, I estimated a probit regression where the binary outcome gave was predicted by treatment. The coefficient on treatment was 0.0868 and statistically significant at the 1% level (p = 0.002), replicating the findings in Table 3, Column 1 of Karlan and List (2007).\nTaken together, these results indicate that individuals are more likely to give when presented with a matching donation opportunity — even without increasing the match ratio. This supports the hypothesis that perceived amplification of one’s donation can nudge charitable behavior.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\nimport pandas as pd\ndata = pd.read_stata(\"karlan_list_2007.dta\")\n# Filter only treatment group\nmatch_data = data[data['treatment'] == 1].copy()\n\nfrom scipy.stats import ttest_ind\n\n# Define groups\nratio1 = match_data[(match_data['ratio2'] == 0) & (match_data['ratio3'] == 0)]\nratio2 = match_data[match_data['ratio2'] == 1]\nratio3 = match_data[match_data['ratio3'] == 1]\n\n# T-tests\nt_1v2 = ttest_ind(ratio1['gave'], ratio2['gave'], equal_var=False)\nt_2v3 = ttest_ind(ratio2['gave'], ratio3['gave'], equal_var=False)\n\nprint(t_1v2)\nprint(t_2v3)\n\n# Define baseline 1:1 match group\nmatch_data['ratio1'] = ((match_data['ratio2'] == 0) & (match_data['ratio3'] == 0)).astype(int)\n\nimport statsmodels.formula.api as smf\n# Regression: gave ~ ratio1 + ratio2 + ratio3 (although only two are needed since ratio1 is implied)\nmodel = smf.ols('gave ~ ratio2 + ratio3', data=match_data).fit()\nprint(model.summary())\n\nratio2_effect = model.params['ratio2']\nratio3_effect = model.params['ratio3']\ndiff_2v3 = ratio3_effect - ratio2_effect\n\n{\n    \"2:1 vs 1:1 (ratio2 coef)\": ratio2_effect,\n    \"3:1 vs 2:1 (diff)\": diff_2v3\n}\n\nTtestResult(statistic=-0.965048975142932, pvalue=0.33453078237183076, df=22225.07770983836)\nTtestResult(statistic=-0.05011581369764474, pvalue=0.9600305476940865, df=22260.84918918778)\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.000\nMethod:                 Least Squares   F-statistic:                    0.6454\nDate:                Sat, 19 Apr 2025   Prob (F-statistic):              0.524\nTime:                        22:04:04   Log-Likelihood:                 16688.\nNo. Observations:               33396   AIC:                        -3.337e+04\nDf Residuals:                   33393   BIC:                        -3.334e+04\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.0207      0.001     14.912      0.000       0.018       0.023\nratio2         0.0019      0.002      0.958      0.338      -0.002       0.006\nratio3         0.0020      0.002      1.008      0.313      -0.002       0.006\n==============================================================================\nOmnibus:                    38963.957   Durbin-Watson:                   1.995\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          2506478.937\nSkew:                           6.511   Prob(JB):                         0.00\nKurtosis:                      43.394   Cond. No.                         3.73\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n{'2:1 vs 1:1 (ratio2 coef)': 0.0018842510217149957,\n '3:1 vs 2:1 (diff)': 0.00010002398025294552}\n\n\nTo evaluate whether larger match ratios increase donation rates, I analyzed only the treatment group and compared response rates across the three match levels: 1:1, 2:1, and 3:1.\nI first conducted t-tests between each pair of match conditions: - The comparison between the 1:1 and 2:1 match ratios yielded a p-value of 0.335, indicating no statistically significant difference. - The 2:1 vs 3:1 match comparison also resulted in a non-significant p-value of 0.960.\nNext, I regressed the donation indicator gave on the match ratio dummy variables ratio2 and ratio3, with 1:1 serving as the baseline category. The regression showed: - A coefficient of 0.0019 for 2:1 (p = 0.338) - A coefficient of 0.0020 for 3:1 (p = 0.313)\nThese coefficients suggest that while both higher match ratios slightly increased the probability of donating compared to 1:1, neither effect was statistically significant.\nFinally, I calculated the difference in fitted effects: - 3:1 vs 2:1 match ratio: 0.0001, again showing virtually no difference.\nThese findings confirm the authors’ conclusion that while offering a match increases donations, increasing the match ratio (from 1:1 to 2:1 or 3:1) does not provide additional lift. This result supports the idea that donors respond to the presence of a match more than to its magnitude.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\nimport pandas as pd\n\ndata = pd.read_stata(\"karlan_list_2007.dta\")\n\n# Drop missing values for 'amount' and 'treatment'\nsubset_all = data[['amount', 'treatment']].dropna()\n\n# T-test\nt_amount_all = ttest_ind(\n    subset_all[subset_all['treatment'] == 1]['amount'],\n    subset_all[subset_all['treatment'] == 0]['amount'],\n    equal_var=False\n)\n\n# Linear regression\nmodel_all = smf.ols('amount ~ treatment', data=subset_all).fit()\n\nprint(t_amount_all)\nprint(model_all.summary())\n\nsubset_donors = data[(data['gave'] == 1)][['amount', 'treatment']].dropna()\n\n# T-test\nt_amount_donors = ttest_ind(\n    subset_donors[subset_donors['treatment'] == 1]['amount'],\n    subset_donors[subset_donors['treatment'] == 0]['amount'],\n    equal_var=False\n)\n\n# Regression: conditional on giving\nmodel_donors = smf.ols('amount ~ treatment', data=subset_donors).fit()\n\nprint(t_amount_donors)\nprint(model_donors.summary())\n\nimport matplotlib.pyplot as plt\n\n# Means\nmean_treat = subset_donors[subset_donors['treatment'] == 1]['amount'].mean()\nmean_control = subset_donors[subset_donors['treatment'] == 0]['amount'].mean()\n\n# Plot\nfig, axes = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n\n# Control group\naxes[0].hist(subset_donors[subset_donors['treatment'] == 0]['amount'], bins=30, color='gray')\naxes[0].axvline(mean_control, color='red', linestyle='--', label=f'Mean: {mean_control:.2f}')\naxes[0].set_title(\"Control Group\")\naxes[0].set_xlabel(\"Donation Amount\")\naxes[0].legend()\n\n# Treatment group\naxes[1].hist(subset_donors[subset_donors['treatment'] == 1]['amount'], bins=30, color='blue')\naxes[1].axvline(mean_treat, color='red', linestyle='--', label=f'Mean: {mean_treat:.2f}')\naxes[1].set_title(\"Treatment Group\")\naxes[1].set_xlabel(\"Donation Amount\")\naxes[1].legend()\n\nplt.suptitle(\"Distribution of Donation Amounts (Among Donors Only)\")\nplt.tight_layout()\nplt.show()\n\nTtestResult(statistic=1.9182618934467577, pvalue=0.055085665289183336, df=36216.05660774625)\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Sat, 19 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        22:04:05   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\nTtestResult(statistic=-0.5846089794983359, pvalue=0.5590471865673547, df=557.4599304243758)\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Sat, 19 Apr 2025   Prob (F-statistic):              0.561\nTime:                        22:04:05   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\n\n\n\n\n\nTo understand how the matching offer influenced donation size, I examined both the unconditional and conditional effects of treatment on donation amount.\n\n\nUnconditional Analysis\nIn the full sample (including non-donors), the average donation in the treatment group was slightly higher than in the control group. The regression estimated an increase of $0.15 in donation amount due to treatment, with a p-value of 0.063 — marginally outside conventional thresholds for statistical significance. The corresponding t-test returned a p-value of 0.056. These results suggest that treatment slightly increases overall donation revenue per solicitation, though the evidence is only borderline significant.\n\n\nConditional on Giving\nRestricting the analysis to only those who donated, the story changes. Among donors, the average contribution was $45.54 in the control group and $43.87 in the treatment group. The regression coefficient for treatment was -1.67 (p = 0.561), and the t-test similarly showed no significant difference. This implies that while treatment encourages more people to give, it does not increase how much they give once they decide to donate.\n\n\nVisual Comparison\nThe histogram plots for each group show very similar distributions of donation amounts. Both groups are right-skewed, and the means (marked with red dashed lines) are nearly identical. This further supports the conclusion that matching incentives affect donation participation more than donation size.\nOverall, these findings reinforce the idea that the matching offer works by nudging people to give at all, rather than prompting those already willing to give to give more."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#simulation-experiment",
    "href": "blog/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Simulate 10,000 Bernoulli draws for each group\ncontrol_draws = np.random.binomial(1, 0.018, size=10000)\ntreatment_draws = np.random.binomial(1, 0.022, size=10000)\n\n# Compute difference vector\ndiffs = treatment_draws - control_draws\n\n# Cumulative average of differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, len(diffs) + 1)\n\n# Plot\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Average of Differences')\nplt.axhline(0.004, color='red', linestyle='--', label='True Mean Difference (0.022 - 0.018)')\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.title(\"Law of Large Numbers: Convergence of Mean Difference\")\nplt.legend()\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nTo illustrate the LLN, I simulated 10,000 Bernoulli draws from each distribution and computed the difference in donation outcomes for each simulated pair. Then, I plotted the cumulative average of these differences.\nThe plot shows that although early differences fluctuate, the average steadily converges to the true mean difference (0.004) as the number of observations increases. This mirrors the LLN, which states that sample averages converge to expected values as sample size grows.\n\n\nCentral Limit Theorem\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nsample_sizes = [50, 200, 500, 1000]\ntrue_diff = 0.022 - 0.018\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    diffs = []\n    for _ in range(1000):\n        control_sample = np.random.binomial(1, 0.018, size=n)\n        treatment_sample = np.random.binomial(1, 0.022, size=n)\n        mean_diff = treatment_sample.mean() - control_sample.mean()\n        diffs.append(mean_diff)\n    \n    axes[i].hist(diffs, bins=30, color='skyblue', edgecolor='black')\n    axes[i].axvline(0, color='black', linestyle='--')\n    axes[i].axvline(true_diff, color='red', linestyle='--', label=f'True Diff = {true_diff:.4f}')\n    axes[i].set_title(f'Sample Size: {n}')\n    axes[i].legend()\n\nplt.suptitle(\"Central Limit Theorem: Sampling Distribution of Mean Differences\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nTo illustrate the CLT, I simulated the difference in average donation outcomes between treatment and control groups across varying sample sizes (n = 50, 200, 500, 1000), repeating the process 1,000 times for each size.\nThe histograms below show the distribution of these 1,000 average differences. As expected: - Smaller samples (n = 50) produce more spread-out, irregular distributions. - Larger samples (n = 1000) produce narrow, bell-shaped distributions centered closer to the true difference (0.004).\nThis highlights that the sampling distribution of the mean becomes approximately normal and tighter with larger sample sizes — the core insight behind the CLT. It also justifies the use of t-statistics and confidence intervals in experimental data analysis.\nTogether, these simulations reinforce why large samples yield more reliable statistical inference."
  }
]